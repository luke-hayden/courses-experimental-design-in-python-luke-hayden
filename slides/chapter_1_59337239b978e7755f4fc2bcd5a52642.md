---
title: Insert title here
key: 59337239b978e7755f4fc2bcd5a52642

---
## Our first hypothesis test: Student's t-test

```yaml
type: "TitleSlide"
key: "5032bdf388"
```

`@lower_third`

name: Luke Hayden
title: Postdoctoral Researcher, ENS de Lyon


`@script`
Our first hypothesis test: Student's t-test


---
## From observed pattern to reliable result

```yaml
type: "FullSlide"
key: "9622562193"
```

`@part1`
Where variation is present, we can see many different patterns in our data. 


Some of these are real, while others are just the results of chance. 


How can we work out whether a perceived difference is real?


`@script`
As we have seen from our exploratory data analysis, it is possible to find all kinds of patterns in our data. Some of these are expected, while others are more surprising. However, most datasets also include random variation. Knowing that, how can go from a simple observation to a reliable result?


---
## Are these groups different?

```yaml
type: "TwoColumns"
key: "80ecf60b08"
```

`@part1`
We have the weights for two groups of adults. Both samples contain variation. 

**Sample A:**


```

[58.2, 69.8,64.7,69.6,78.1]
```




**Sample B:**

```

[83.7,78.5, 78.6, 86.9, 84.4]

```

Are these different?


`@part2`
![](https://raw.githubusercontent.com/luke-hayden/courses-experimental-design-in-python-luke-hayden/master/bar.png)


`@script`
Let's take a really simple example. Let's say we have the body weights of two samples from two groups of people, A and B. From our small number of samples, we seem to see a trend, whereby the group mean for sample A is bigger than that for sample B. Now we need to ask whether this difference is reliable. Is this difference enough for us to draw any conclusions.


---
## Null hypothesis vs alternative hypothesis

```yaml
type: "TwoRowsTwoColumns"
key: "1adfecb6ee"
```

`@part1`
**Null hypothesis**

No difference between group A and group B. 
Both groups have the same mean population-level mean. 

_A = B_


`@part2`
**![](https://raw.githubusercontent.com/luke-hayden/courses-experimental-design-in-python-luke-hayden/master/unimod.png)**


`@part3`
**Alternative hypothesis**

This is the "more interesting" alternative: these two populations are meaningfully different. 

_A != B_


`@part4`
![](https://raw.githubusercontent.com/luke-hayden/courses-experimental-design-in-python-luke-hayden/master/bimod.png)


`@script`
In order to draw a conclusion, we will need to distinguish between two cases, two different hypotheses.


---
## Some statistical terms

```yaml
type: "FullSlide"
key: "17c0b4b679"
```

`@part1`
**p-value**

A p-value can quantify how likely it is that we would observe a particular pattern under the **null hypothesis.** A low p-value means that it's very unlikely that the observed pattern would have emerged under the null hypothesis. 

**alpha**

Alpha is the term used for the crucial threshold of p-value, below which we would reject the null hypothesis. Usually: 

_alpha < 0.05: reject null hypothesis_


`@script`



---
## Student's t-test (two-sample)

```yaml
type: "TwoColumns"
key: "ee2f383474"
```

`@part1`
**Background**

Invented by William Sealy Gosset, while working on methods to test beer quality. 

**Use**

Given two samples, tests whether the means of the populations from which these samples are drawn are equal.


`@part2`
**Implementing a two-sample t-test**

```

from scipy import stats 

stats.ttest_ind(X, Y)

[t_stat, p-value]

```


`@script`



---
## Implementing a t-test

```yaml
type: "FullCodeSlide"
key: "d94ce2df22"
```

`@part1`
```


from scipy import stats 


Sample_A= [58.2, 69.8,64.7,69.6,78.1]

Sample_B=[83.7,78.5, 78.6, 86.9, 84.4]


t_result=stats.ttest_ind(Sample_A, Sample_B)

print(t_result[1])

if (t_result < 0.05):
print("A and B are different!")


```


`@script`



---
## Now let's try it out!

```yaml
type: "FinalSlide"
key: "5dc84036b6"
```

`@script`


